{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rK6FkgeRrOdN"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 1\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 16.09.2016\n",
    "\n",
    "Срок сдачи: 30.09.2016 23:59MSK\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 1 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    " \n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Кроме того, некоторые из заданий являются опциональными (необязательными), однако за их выполнение можно получить дополнительные баллы, которые позднее будут учитываться при проставлении оценок автоматом по курсу.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник). \n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл \\*.ipynb в соответствии со следующим форматом: *HW1_Username.ipynb*, где *Username* — Ваша фамилия и инициалы на латинице (например, *HW1_IvanovII.ipynb*). Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+141@gmail.com для студентов группы БПМИ-141)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTTfNFwBrOdQ"
   },
   "source": [
    "## Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Bxuvd6V3rOdR"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVXSY_SqrOdX"
   },
   "source": [
    "**1. (0.2 балла)** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XfMO162grOdZ"
   },
   "outputs": [],
   "source": [
    "def max_element(arr):\n",
    "    result = x[1:][x[:-1] == 0]\n",
    "    if result.size == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return result.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFVwKxDFrOde"
   },
   "source": [
    "**2. (0.2 балла)** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "omnR-tcGrOdf"
   },
   "outputs": [],
   "source": [
    "def nearest_value(X, v):\n",
    "    return X.reshape(-1)[np.argmin(abs(X - v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtGr2xRKrOdj"
   },
   "source": [
    "**3. (0.2 балла)** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kUOecoDurOdl",
    "outputId": "bbddc6eb-b756-4887-afaa-f387f3e60725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 0]\n",
      " [4 3 3]\n",
      " [4 4 4]]\n",
      "[[-1.09544512 -0.82158384 -1.91702895]\n",
      " [ 0.54772256  0.          0.54772256]\n",
      " [ 0.54772256  0.82158384  1.36930639]]\n"
     ]
    }
   ],
   "source": [
    "def scale(X):\n",
    "    X = X - np.mean(X, axis = 0)\n",
    "    std = np.std(X)\n",
    "    if std != 0:\n",
    "        return X/np.std(X)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "X = np.random.randint(5, size=(3, 3))\n",
    "print(X)\n",
    "print(scale(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2satwzq4rOdt"
   },
   "source": [
    "**4. (0.2 балла)** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2DoCBrvSrOdv",
    "outputId": "5dfaf921-4b23-4265-bc3a-60f22c40ba4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.20257601   8.74767304   7.59789149]\n",
      " [ 10.15758808   9.33816434   9.8288341 ]\n",
      " [ 10.58207757   9.41026999  11.40669324]]\n",
      "0.815032162407\n",
      "29.9474335896\n",
      "7.59789148821 11.4066932372\n",
      "28.9234719559\n",
      "[  2.87056359e+01   2.33014733e-02   1.21849624e+00]\n",
      "[[ 17.20863813 -34.70269522  18.43984619]\n",
      " [-14.54544611  30.14541706 -16.28689209]\n",
      " [ -3.96491495   7.32465557  -3.58279389]]\n"
     ]
    }
   ],
   "source": [
    "def get_stats(X):\n",
    "    print(np.linalg.det(X))\n",
    "    print(np.trace(X))\n",
    "    print(X.min(), X.max())\n",
    "    print(np.linalg.norm(X, 'fro'))\n",
    "    print(np.linalg.eigvals(X))\n",
    "    print(np.linalg.inv(X))\n",
    "    \n",
    "N = 1 * np.random.randn(3, 3) + 10\n",
    "print(N)\n",
    "get_stats(N)\n",
    "\n",
    "X = np.empty(100) # для следующего задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0piZF9XjrOd1"
   },
   "source": [
    "**5. (0.2 балла)** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-hAi5EgNrOd3",
    "outputId": "9130d6f2-67db-40c1-9ca7-0e881cd6a0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.40213171574\n",
      "11.8743005818\n"
     ]
    }
   ],
   "source": [
    "for exp_num in range(100):\n",
    "    A = np.random.randn(10, 10)\n",
    "    B = np.random.randn(10, 10)\n",
    "    X[exp_num - 1] = A.dot(B).max()\n",
    "print(np.mean(X))\n",
    "print(np.percentile(X, 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTZko_BErOd8"
   },
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "[Данные](https://www.dropbox.com/s/dvfitn93obn0rql/2008.csv?dl=0) и их [описание](http://stat-computing.org/dataexpo/2009/the-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YsLglBn2rOd-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sgEBCBJrOeC"
   },
   "source": [
    "**6. (0.3 балла)** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FL-i6NN8rOeF",
    "outputId": "d33c50b2-7dcd-4c18-fda1-85db94fecb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2008.csv')\n",
    "#data = data[(data.Month >= 1) & (data.Month <= 4)] - на случай, если данные нужно брать действительно только за 4 месяца\n",
    "print(data['CancellationCode'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhShxsdIrOeK"
   },
   "source": [
    "**7. (0.3 балла)** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Tiul67AwrOeM",
    "outputId": "baa2c54d-359b-4346-a8c6-fbd43761dc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724.5082571428571 31 4962\n"
     ]
    }
   ],
   "source": [
    "print(data['Distance'].mean(), data['Distance'].min(), data['Distance'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rD-rSANKrOeT"
   },
   "source": [
    "**8. (0.3 балла)** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Hs7yApmXrOeV",
    "outputId": "370b6a11-d66f-42ec-bc4a-f08bedc17655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Month  DayofMonth  FlightNum Origin Dest\n",
      "1116      12          30         65    WRG  PSG\n",
      "6958      12          26         65    WRG  PSG\n",
      "17349      8          18         64    PSG  WRG\n",
      "27534      3          11         64    PSG  WRG\n",
      "46082      8           9         65    WRG  PSG\n",
      "48112      2          28         64    PSG  WRG\n",
      "FlightNum  Distance\n",
      "64         1747        6\n",
      "           82          5\n",
      "           1005        5\n",
      "           123         4\n",
      "           533         4\n",
      "           571         3\n",
      "           680         3\n",
      "           2381        2\n",
      "           359         1\n",
      "           372         1\n",
      "           414         1\n",
      "           883         1\n",
      "65         82          6\n",
      "           1747        6\n",
      "           581         4\n",
      "           1005        4\n",
      "           372         3\n",
      "           571         3\n",
      "           2454        3\n",
      "           123         2\n",
      "           680         2\n",
      "           281         1\n",
      "           386         1\n",
      "           682         1\n",
      "Name: Distance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[data.Distance == data.Distance.min()][['Month', 'DayofMonth', 'FlightNum', 'Origin', 'Dest']])\n",
    "weird_flight_numbers = data[data.Distance == data.Distance.min()]['FlightNum']\n",
    "weird_data = data[data.FlightNum.isin(weird_flight_numbers) == True & (data.Distance != data.Distance.min())]\n",
    "print(weird_data.groupby('FlightNum')['Distance'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5XI5lKCrOeb"
   },
   "source": [
    "<img src = \"https://pp.vk.me/c638918/v638918390/4c16/UXP6yu3qEts.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0g53yRsrOec"
   },
   "source": [
    "**9. (0.3 балла)** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kWN5jX8PrOee",
    "outputId": "26dbbc14-e846-4df8-dd31-c31252d64d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL\n",
      "['Atlanta']\n"
     ]
    }
   ],
   "source": [
    "airport_data = pd.read_csv('airports.csv')\n",
    "iata_code = data['Origin'].value_counts().idxmax()\n",
    "print(iata_code)\n",
    "print(airport_data[airport_data.iata == iata_code]['city'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RgWPITzrOej"
   },
   "source": [
    "**10. (0.3 балла)** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ouSyFBzgrOek",
    "outputId": "aeabf339-6b6e-44d7-fe0d-16d4e944ed07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJU\n"
     ]
    }
   ],
   "source": [
    "air_time = data.groupby('Origin')['AirTime'].mean()\n",
    "print(air_time.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beLS86bxrOes"
   },
   "source": [
    "**11. (0.5 балла)** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8RA-Z1lfrOet",
    "outputId": "6b05a9ba-32b4-4c92-b83b-60c25b6a2aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWR\n"
     ]
    }
   ],
   "source": [
    "new_data = data.groupby('Origin').filter(lambda x: x['Origin'].value_counts() >= 1000)\n",
    "print((new_data['Origin'][new_data.DepDelay > 0].value_counts()/new_data['Origin'].value_counts()).idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QORT-o4OrOe1"
   },
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов. \n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12. (0.5 балла)** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "16BAlyzXrOe3",
    "outputId": "731702f0-ff75-43fc-84c0-ca697b547a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- True\n",
      "- 355215\n",
      "- 70000\n",
      "- 16\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2008.csv')\n",
    "print('-', data.isnull().any().any())\n",
    "print('-', data.isnull().sum().sum())\n",
    "print('-', data.isnull().any(1).sum())\n",
    "print('-', data.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qynC0gXRrOfC"
   },
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "- Имеются ли пропущенные значения в целевой переменной?\n",
    "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
    "\n",
    "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9zEDMY4erOfE",
    "outputId": "87df1aa6-03ff-4ff0-bcb1-1fa272039514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- True \n",
      "\n",
      "Missing features in our data without target variable: \n",
      "['DepTime' 'ArrTime' 'TailNum' 'ActualElapsedTime' 'CRSElapsedTime'\n",
      " 'AirTime' 'ArrDelay' 'DepDelay' 'TaxiIn' 'TaxiOut' 'CarrierDelay'\n",
      " 'WeatherDelay' 'NASDelay' 'SecurityDelay' 'LateAircraftDelay'] \n",
      "\n",
      "Patially missing features in our data without target variable: \n",
      "['TailNum' 'CRSElapsedTime']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>1325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N636AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15680</th>\n",
       "      <td>954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N21537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>1806.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N288SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20622</th>\n",
       "      <td>844.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N505MJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22462</th>\n",
       "      <td>2132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N17231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30057</th>\n",
       "      <td>1358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N506CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33611</th>\n",
       "      <td>826.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N437SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37581</th>\n",
       "      <td>2234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N560SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40343</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N921EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50401</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N750SK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50810</th>\n",
       "      <td>1559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N581SW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67078</th>\n",
       "      <td>1517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N19554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DepTime  ArrTime TailNum  ActualElapsedTime  CRSElapsedTime  AirTime  \\\n",
       "5976    1325.0      NaN  N636AS                NaN            53.0      NaN   \n",
       "15680    954.0      NaN  N21537                NaN           137.0      NaN   \n",
       "16382   1806.0      NaN  N288SW                NaN            59.0      NaN   \n",
       "20622    844.0      NaN  N505MJ                NaN           114.0      NaN   \n",
       "22462   2132.0      NaN  N17231                NaN            58.0      NaN   \n",
       "30057   1358.0      NaN  N506CA                NaN           150.0      NaN   \n",
       "33611    826.0      NaN  N437SW                NaN           165.0      NaN   \n",
       "37581   2234.0      NaN  N560SW                NaN            43.0      NaN   \n",
       "40343   1440.0      NaN  N921EV                NaN           106.0      NaN   \n",
       "50401   2232.0      NaN  N750SK                NaN            97.0      NaN   \n",
       "50810   1559.0      NaN  N581SW                NaN            45.0      NaN   \n",
       "67078   1517.0      NaN  N19554                NaN            65.0      NaN   \n",
       "\n",
       "       ArrDelay  DepDelay  TaxiIn  TaxiOut  CarrierDelay  WeatherDelay  \\\n",
       "5976        NaN      24.0     NaN      NaN           NaN           NaN   \n",
       "15680       NaN      19.0     NaN      NaN           NaN           NaN   \n",
       "16382       NaN      38.0     NaN     11.0           NaN           NaN   \n",
       "20622       NaN      -1.0     NaN      NaN           NaN           NaN   \n",
       "22462       NaN      -2.0     NaN     28.0           NaN           NaN   \n",
       "30057       NaN      28.0     NaN      NaN           NaN           NaN   \n",
       "33611       NaN      -4.0     NaN      NaN           NaN           NaN   \n",
       "37581       NaN      -1.0     NaN     16.0           NaN           NaN   \n",
       "40343       NaN      -5.0     NaN      NaN           NaN           NaN   \n",
       "50401       NaN      -2.0     NaN     21.0           NaN           NaN   \n",
       "50810       NaN      -7.0     NaN     10.0           NaN           NaN   \n",
       "67078       NaN       7.0     NaN      NaN           NaN           NaN   \n",
       "\n",
       "       NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "5976        NaN            NaN                NaN  \n",
       "15680       NaN            NaN                NaN  \n",
       "16382       NaN            NaN                NaN  \n",
       "20622       NaN            NaN                NaN  \n",
       "22462       NaN            NaN                NaN  \n",
       "30057       NaN            NaN                NaN  \n",
       "33611       NaN            NaN                NaN  \n",
       "37581       NaN            NaN                NaN  \n",
       "40343       NaN            NaN                NaN  \n",
       "50401       NaN            NaN                NaN  \n",
       "50810       NaN            NaN                NaN  \n",
       "67078       NaN            NaN                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-', data['DepDelay'].isnull().any(), '\\n')\n",
    "data_without_target = data[data.DepDelay.isnull()]\n",
    "\n",
    "mis_feat = data_without_target.iloc[0, data_without_target.isnull().any().nonzero()].index.values\n",
    "part_mis_feat = data_without_target[mis_feat].iloc[0, data_without_target[mis_feat].notnull().any().nonzero()].index.values\n",
    "print('Missing features in our data without target variable: ')\n",
    "print(mis_feat, '\\n')\n",
    "print('Patially missing features in our data without target variable: ')\n",
    "print(part_mis_feat)\n",
    "\n",
    "data[data.Cancelled == 1 & data.DepDelay.notnull()][mis_feat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFvvkjFKrOfJ"
   },
   "source": [
    "Итак, мы видим, что все авиарейсы с отсутствющим значением 'DepDelay' были отменены (в связи с чем у них отсутствуют значения таких связанных с полетом признаков, как время вылета, время прибытия, действительное время полета и проч.). Тем не менее, существует 12 авиарейсов, которые были отменены ('Cancelled' value = 1), но целевая переменная присутствует. В отличие от объектов с отсутствующим значением целевой переменной, у них у всех присутствует время вылета (а так же бортовой номер и ожидаемое время полета - хотя эти два признака частично присутствуют при 'DepDelay' = NaN), но так же отсутствует время прибытия и действительное время полета. Таким образом, несмотря на присутствие значения целевого признака, принимая во внимание малую долю таких объектов и ошибочность данных (полеты были отменены, а не задержаны), можно исключить из рассмотрения признаки 'Cancelled' и 'CancellationCode', а так же эти 12 авиарейсов (считая значение 'DepDelay' для них некорректным - должно отсутствовать) - таким образом, значение 'Cancelled' у всех интересующих нас объектов будет равно 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ur526BeTrOfK"
   },
   "outputs": [],
   "source": [
    "data = data[data.DepDelay.notnull() & (data.DepDelay != 0) & (data.Cancelled != 1)]\n",
    "data.drop(['Cancelled', 'CancellationCode'], axis = 1, inplace = True)\n",
    "\n",
    "depdelay = data['DepDelay']\n",
    "data.drop('DepDelay', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4cpB5u7rOfN"
   },
   "source": [
    "**13. (0.5 балла)** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать. \n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Uj6kdPx8rOfO"
   },
   "outputs": [],
   "source": [
    "def get_hours(time):\n",
    "    return time//100\n",
    "def get_minutes(time):\n",
    "    return time%100\n",
    "\n",
    "hours = data[['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']].apply(get_hours)\n",
    "minutes = data[['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']].apply(get_minutes)\n",
    "data[['DepTime_Hour', 'CRSDepTime_Hour', 'ArrTime_Hour', 'CRSArrTime_Hour']] = hours\n",
    "data[['DepTime_Minute', 'CRSDepTime_Minute', 'ArrTime_Minute', 'CRSArrTime_Minute']] = minutes\n",
    "data.drop(['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4oMzxParOfS"
   },
   "source": [
    "**14. (0.5 балла)** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-oQdmO6CrOfS",
    "outputId": "ff0a1b8e-4254-4b7c-ea90-c1e324d190aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n",
      "[True]\n",
      "ArrDelay 0.933525938482\n",
      "[True]\n"
     ]
    }
   ],
   "source": [
    "def minutes(hours, minutes):\n",
    "    return 60*hours + minutes\n",
    "\n",
    "# явное вычисление задержки отправления ('DepDelay'), при проверке учтем случай 'перехода' через сутки\n",
    "diff_crs_dep = minutes(data.DepTime_Hour, data.DepTime_Minute) - minutes(data.CRSDepTime_Hour, data.CRSDepTime_Minute)\n",
    "\n",
    "# проверка зависимости на объектах выборки\n",
    "print(((diff_crs_dep == depdelay) | (abs(diff_crs_dep - depdelay) == 1440.0)).unique())\n",
    "\n",
    "# еще одно явное вычисление задержки отправления\n",
    "diff_crs_elaps = data.CRSElapsedTime - (data.ActualElapsedTime - data.ArrDelay)\n",
    "\n",
    "# проверка зависимости на объектах выборки\n",
    "print(((diff_crs_elaps == depdelay) | data.ActualElapsedTime.isnull()).unique())\n",
    "\n",
    "# поиск признаков, сильно коррелирующих с ответами \n",
    "# (будем считать значение коэффициента корреляции, большее 90%, достаточным основанием для удаления признака)\n",
    "for col in data.columns:\n",
    "    if data[col].dtype != 'object' and data[col].corr(depdelay) > 0.9:\n",
    "        print(col, data[col].corr(depdelay))\n",
    "\n",
    "# явное вычисление задержки прибытия, при проверке учтем случай 'перехода' через сутки\n",
    "diff = minutes(data.ArrTime_Hour, data.ArrTime_Minute) - minutes(data.CRSArrTime_Hour, data.CRSArrTime_Minute)\n",
    "\n",
    "# проверка зависимости на объектах выборки\n",
    "print(((diff == data.ArrDelay) | (abs(diff - data.ArrDelay) == 1440.0) | data.ArrDelay.isnull()).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HjOqYvEerOfX"
   },
   "source": [
    "Заметим, что одновременное наличие таких признаков, как:\n",
    "* DepTime и CRSDepTime (их производных Hour и Minute)\n",
    "* ActualElapsedTime, CRSElapsedTime и ArrDelay\n",
    "\n",
    "приводит к явной зависимости от ответа (т. е. позволяет получать значение целевой переменной, что не допускает такой характеристики поставленной задачи как \"предсказание\")\n",
    "\n",
    "Также заметим, что найденный нами сильно коррелирующий с ответом признак ArrDelay явно выражается через значения признаков:\n",
    "* ArrTime и CRSArrTime (их производных Hour и Time)\n",
    "\n",
    "Несмотря на проделанную поиск по выявлению признаков, содержащих большую долю информации о значении целевой переменной, существует еще одна корреляция, основанная на данных датасета (все предыдущие зависимости очевидным образом следуют из свойств имеющихся признаков, что и позволяло проверить эту зависимость для всех объектов). Это сумма всех 'Cause of Delay' (http://www.transtats.bts.gov/Fields.asp?Table_ID=236) - коэффициент корреляции с ответом оказывается больше 90%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JKbl6hILrOfY",
    "outputId": "4f58fe45-f4b4-474a-b002-6f47e9e8c032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932965824381\n"
     ]
    }
   ],
   "source": [
    "sum = (data['CarrierDelay'] + data['WeatherDelay'] + data['NASDelay'] + data['SecurityDelay'] + data['LateAircraftDelay'])\n",
    "print(sum.corr(depdelay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VZhOm2irOfh"
   },
   "source": [
    "Таким образом, у нас возникает большой выбор признаков, необходимых для удаления в связи со значимым влиянием на прогноз:\n",
    "* (DepTime_Hour и DepTime_Minute) или (CRSDepTime_Hour и CRSDepTime_Minute)\n",
    "* ActualElapsedTime, CRSElapsedTime или ArrDelay\n",
    "* ArrDelay\n",
    "* (ArrTime_Hour и ArrTime_Minute) или (CRSArrTime_Hour и CRSArrTime_Minute)\n",
    "\n",
    "Исключим признаки, связанные с запланированными данными, и уберем один из признаков 'Cause of Delay' - например, 'CarrierDelay' (проверим, что полученная сумма с ответом коррелирует уже не сильно):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GdciToHjrOfj",
    "outputId": "7a648de2-fff9-41f3-d403-0e96efa09416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.635820351184\n"
     ]
    }
   ],
   "source": [
    "sum = (data['WeatherDelay'] + data['NASDelay'] + data['SecurityDelay'] + data['LateAircraftDelay'])\n",
    "print(sum.corr(depdelay))\n",
    "\n",
    "data.drop(['CRSDepTime_Hour', 'CRSDepTime_Minute', 'CRSElapsedTime'], axis = 1, inplace = True)\n",
    "data.drop(['ArrDelay', 'CRSArrTime_Hour', 'CRSArrTime_Minute'], axis = 1, inplace = True)\n",
    "data.drop(['CarrierDelay'], axis = 1, inplace = True)\n",
    "\n",
    "data.drop(['Year', 'TailNum'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YruTtyiGrOfo"
   },
   "source": [
    "**15. (1 балл)** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhW7BmwNrOfp"
   },
   "source": [
    "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SM9izgr_rOfq",
    "outputId": "5d54d4ad-38f9-455f-b1ed-25b04501bbb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa7f1c84588>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngJlZh3kRMDPrMC8CZmYd9v8B8qCY6Msr8QsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7f1c84dd8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['DepTime_Hour'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LVDZOHYvrOfu",
    "outputId": "3dfadc47-9f20-4571-bad7-8fd1ad349547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa7f1c699e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq+VCYWZmtVwozMyslguFmZnV+n/0i5iFhqbMIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7f1c18240>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['TaxiIn'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3Q1PkPx5rOfz",
    "outputId": "e37dd3d3-9ea7-44bf-f0d5-77d09db731c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa7f1c4e940>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7f1c2bc18>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['FlightNum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiLu4TN6rOf2"
   },
   "source": [
    "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SelpVZu0rOf3"
   },
   "source": [
    "Признаки будут вносить неодинаковый вклад - например, номер полета при обучении линейной регрессии будет влиять на целевую переменную гораздо сильнее, чем значения признаков 'DepTime_Hour' и 'TimeIn', которые оказываются сильно меньше соответствующих значений признака 'FlightNum'. Масштабирование поможет принять во внимание все признаки. Более того, отсутствие нормализации усложняет метод градиентного спуска (скорость сходимости метода значительно уменьшается), делая его при неаккуратном выборе длины шага непродуктивным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0_FNa9KrOf4"
   },
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iLvrPHd4rOf6"
   },
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    categorical_features = (data.dtypes == \"object\").values\n",
    "\n",
    "    cat_data = data[data.columns[categorical_features]].fillna(value = 'nan')\n",
    "    noncat_data = data[data.columns[~categorical_features]].fillna(value = 0)\n",
    "\n",
    "    noncat_data_norm_np = StandardScaler().fit_transform(noncat_data)\n",
    "    noncat_data_norm = pd.DataFrame(data = noncat_data_norm_np, index = data.index, \n",
    "                                    columns = data.columns[~categorical_features])\n",
    "    cat_data_hot = pd.get_dummies(cat_data)\n",
    "    \n",
    "    return pd.concat([noncat_data_norm, cat_data_hot], axis = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIUR3kjtrOf9"
   },
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "plLcw-aRrOf_",
    "outputId": "bf5377ed-f80d-4380-b8db-2cf6bd1d6277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features: 632\n"
     ]
    }
   ],
   "source": [
    "data = transform_data(data)\n",
    "print(\"Count of features:\", data.columns.values.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p1gexwJkrOgC"
   },
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aTSOz2eirOgE",
    "outputId": "1991e829-6aa0-4e70-9bc5-6c6c203361ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 44374\n",
      "test size: 19018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data_train, data_test, depdelay_train, depdelay_test = train_test_split(data, depdelay, test_size = 0.3)\n",
    "print('train size:', data_train.index.values.size)\n",
    "print('test size:', data_test.index.values.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0AZsG_SrOgH"
   },
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17. (0.5 балла)** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AW6GS71krOgJ",
    "outputId": "1a6efe8a-8c88-45f7-efbd-aa134134c151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on small part of train: 201.108352173\n",
      "R^2 on small part of train: 0.829739417728\n",
      "MSE on test: 1.12693157192e+25\n",
      "R^2 on test: -8.46348241654e+21\n",
      "\n",
      "\n",
      "         features       weights\n",
      "count  632.000000  6.320000e+02\n",
      "mean   315.500000 -1.548756e+12\n",
      "std    182.586966  5.110602e+12\n",
      "min      0.000000 -2.608872e+13\n",
      "25%    157.750000 -2.019772e+12\n",
      "50%    315.500000 -1.971285e+12\n",
      "75%    473.250000  0.000000e+00\n",
      "max    631.000000  7.322977e+13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "part_coef = 1000\n",
    "\n",
    "part_train = data_train[:part_coef]\n",
    "part_y_train = depdelay_train[:part_coef]\n",
    "\n",
    "LR = LinearRegression().fit(part_train, part_y_train)\n",
    "print('MSE on small part of train:',\n",
    "      mean_squared_error(y_true = part_y_train, y_pred = LR.predict(part_train)))\n",
    "print('R^2 on small part of train:',\n",
    "      LR.score(part_train, part_y_train))\n",
    "\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = LR.predict(data_test)))\n",
    "print('R^2 on test:', LR.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "print(pd.DataFrame({'features': data.columns.values, 'weights': LR.coef_}).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rIAn1GwjrOgN"
   },
   "source": [
    "Уже на 1000 объектах (из 44382) нашей обучающей выборки линейная регрессия переобучается, выдавая хороший результат на самих объектах, выбранных для обучения, но очень плохой на контрольной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMH9tg2SrOgO"
   },
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество.\n",
    "\n",
    "**18. (0.5 балла)** Обучите линейные регрессии с L1- и L2-регуляризатором, подобрав лучшее значение параметра регуляризации из списка alpha_grid при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах, что и в п.17. Выведите значения $MSE$ и $R^2$ на обучающей и контрольной выборках. Удалось ли решить указанные вами ранее проблемы?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "33kYUWuBrOgO",
    "outputId": "2d423180-a157-437f-d0ba-596f97c0d1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, trained on small part of train:\n",
      "MSE on test: 1.12693157192e+25\n",
      "R^2 on test: -8.46348241654e+21\n",
      "\n",
      "\n",
      "LR, trained on a data_train:\n",
      "MSE on test: 521.808544851\n",
      "R^2 on test: 0.608111303812\n",
      "\n",
      "\n",
      "Lasso, trained on small part of train:\n",
      "MSE on test: 505.556842368\n",
      "R^2 on test: 0.620316658745\n",
      "\n",
      "\n",
      "Lasso, trained on a data_train:\n",
      "MSE on test: 485.503523628\n",
      "R^2 on test: 0.635377103831\n",
      "\n",
      "\n",
      "Ridge, trained on small part of train:\n",
      "MSE on test: 507.070422869\n",
      "R^2 on test: 0.619179929392\n",
      "\n",
      "\n",
      "Ridge, trained on a data_train:\n",
      "MSE on test: 484.973773278\n",
      "R^2 on test: 0.635774956982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "LR = LinearRegression().fit(part_train, part_y_train)\n",
    "print('LR, trained on small part of train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = LR.predict(data_test)))\n",
    "print('R^2 on test:', LR.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "LR = LinearRegression().fit(data_train, depdelay_train)\n",
    "print('LR, trained on a data_train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = LR.predict(data_test)))\n",
    "print('R^2 on test:', LR.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "lasso_cv = LassoCV(cv = 5).fit(part_train, part_y_train)\n",
    "print('Lasso, trained on small part of train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = lasso_cv.predict(data_test)))\n",
    "print('R^2 on test:', lasso_cv.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "lasso_cv = LassoCV(cv = 5).fit(data_train, depdelay_train)\n",
    "print('Lasso, trained on a data_train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = lasso_cv.predict(data_test)))\n",
    "print('R^2 on test:', lasso_cv.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "ridge_cv = RidgeCV(cv = 5).fit(part_train, part_y_train)\n",
    "print('Ridge, trained on small part of train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = ridge_cv.predict(data_test)))\n",
    "print('R^2 on test:', ridge_cv.score(data_test, depdelay_test))\n",
    "print('\\n')\n",
    "\n",
    "ridge_cv = RidgeCV(cv = 5).fit(data_train, depdelay_train)\n",
    "print('Ridge, trained on a data_train:')\n",
    "print('MSE on test:', mean_squared_error(y_true = depdelay_test, y_pred = ridge_cv.predict(data_test)))\n",
    "print('R^2 on test:', ridge_cv.score(data_test, depdelay_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "diNIkQ0UrOgS",
    "outputId": "b441661d-df3a-4515-ea74-9a44e7c460ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10956\n",
      "19018\n"
     ]
    }
   ],
   "source": [
    "print(((depdelay_test > 0) == (ridge_cv.predict(data_test) > 0)).sum())\n",
    "print(depdelay_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJBCE8F-rOgW"
   },
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "В предыдущем разделе мы использовали существующие реализации методов обучения линейной регрессии с регуляризацией и без. Тем не менее, подобные реализации, как правило, имеются лишь для ограниченного набора стандартных методов. В частности, при выходе функционала качества за пределы стандартного множества необходимо самостоятельно реализовывать составляющие процесса решения оптимизационной задачи. Именно этому и посвящен данный раздел задания.\n",
    "\n",
    "Пусть необходимо минимизировать следующий функционал (Mean Square Percentage Error — модифицированный [RMSPE](https://www.kaggle.com/c/rossmann-store-sales/details/evaluation)):\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2,$$\n",
    "\n",
    "где $\\{x_i, y_i\\}_{i=1}^l$ — обучающая выборка, $w$ — вектор весов линейной модели. Будем также рассматривать функционал $MSPE$ с L2-регуляризацией:\n",
    "\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2 + ||w||_2^2.$$\n",
    "\n",
    "**19. (0 баллов)** Добавьте к объектам обеих выборок из п. 16 единичный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GOZMvcvmrOgY",
    "outputId": "68819022-da9f-40a6-ede8-c6715f327f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c\n",
      "0  1.0  0.0  0.0\n",
      "1  0.0  1.0  0.0\n",
      "2  0.0  0.0  1.0\n",
      "3  1.0  0.0  0.0\n",
      "     a    b    c\n",
      "0  1.0  NaN  NaN\n",
      "1  NaN  1.0  NaN\n",
      "2  NaN  NaN  1.0\n",
      "3  1.0  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(list('abca'))\n",
    "s = pd.get_dummies(s, sparse = True)\n",
    "print(s)\n",
    "print(s.to_sparse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbWUJT57rOgd"
   },
   "source": [
    "**20. (1 балл)** Реализуйте функции, которые вычисляют:\n",
    " * прогнозы линейной модели;\n",
    " * функционал $MSPE$ и его градиент;\n",
    " * регуляризованный $MSPE$ и его градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lQK5DA81rOge"
   },
   "outputs": [],
   "source": [
    "# возвращает вектор прогнозов линейной модели с вектором весов w для выборки X\n",
    "def make_pred(X, w):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "FJgLfpSwrOgh"
   },
   "outputs": [],
   "source": [
    "# возвращает значение функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "75vZlRNurOgo"
   },
   "outputs": [],
   "source": [
    "# возвращает градиент функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "DK5lAZGMrOgr"
   },
   "outputs": [],
   "source": [
    "# возвращает значение регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "geGjtqZkrOgx"
   },
   "outputs": [],
   "source": [
    "# возвращает градиент регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRrL0kfVrOgz"
   },
   "source": [
    "**21. (1 балл)** Реализуйте метод градиентного спуска для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна принимать следующие параметры:\n",
    " - X — матрица \"объект-признак\";\n",
    " - y — вектор целевой переменной;\n",
    " - w0 — начальное значение вектора весов;\n",
    " - step_size — значение темпа обучения;\n",
    " - max_iter — максимальное число итераций;\n",
    " - eps — значение, используемое в критерии останова;\n",
    " - is_reg — бинарный параметр, принимает значение True в случае наличия регуляризации функционала, False — в противном случае.\n",
    " \n",
    "Процесс должен быть остановлен, если выполнено хотя бы одно из следующих условий:\n",
    " - было выполнено заданное количество итераций max_iter;\n",
    " - евклидова норма разности векторов $w$ на соседних итерациях стала меньше, чем eps.\n",
    "\n",
    "Функция должна возвращать полученный в результате оптимизации вектор $w$ и список значений функционала на каждой итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wOQV_R1MrOgz"
   },
   "outputs": [],
   "source": [
    "def grad_descent(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMZcLg7CrOg3"
   },
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации для различных:\n",
    " * значений размера шага из набора [0.001, 1, 10];\n",
    " * способов начальной инициализации вектора весов (нули, случайные веса).\n",
    "\n",
    "Проанализируйте полученные результаты — влияют ли данные параметры на скорость сходимости и итоговое качество? Если да, то как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "k5eTVkUGrOg4"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4PKPRGmrOg-"
   },
   "source": [
    "**22. (0.5 балла)** Обучите линейную регрессию с функционалом MSPE и его регуляризованным вариантом на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации. Исследуйте зависимость скорости сходимости от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "a3xFuCKgrOg_"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xl1FWi4RrOhB"
   },
   "source": [
    "Метод градиентного спуска может быть весьма трудозатратен в случае большого размера обучающей выборки. Поэтому часто используют метод стохастического градиентного спуска, где на каждой итерации выбирается случайный объект из обучающей выборки и обновление весов происходит только по этому объекту. \n",
    "\n",
    "**23. (1 доп. балл)**  Реализуйте метод стохастического градиентного спуска (SGD) для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна иметь параметры и возвращаемое значение, аналогичные оным функции grad\\_descent из п.21. Кроме того, должен использоваться аналогичный критерий останова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nXQaZ5AXrOhC"
   },
   "outputs": [],
   "source": [
    "def sgd(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2sDZDuWrOhF"
   },
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ и его регуляризованным вариантом на обучающей выборке при помощи метода стохастического градиентного спуска, подобрав при этом размер шага, при котором метод будет сходиться. Нарисуйте график сходимости. Выведите значения $MSPE, MSE, R^2$ на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2KJRu1fTrOhF"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vsTCn4D0rOhI"
   },
   "source": [
    "**24. (0.5 доп. балла)** Аналогично п.22 исследуйте зависимость скорости сходимости метода SGD от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KXuU52mkrOhJ"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56eF7OyurOhN"
   },
   "source": [
    "**25. (0.5 балла)** Обучите стандартную линейную регрессию с функционалом качества MSE на обучающей выборке и выведите значение MSPE полученного решения на контрольной выборке. Как оно соотносится с аналогичным результатом для решения, полученного в п.22? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "A_RsHsftrOhO"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IsbLN2ZrOhS"
   },
   "source": [
    "Здесь вы можете поделиться своими мыслями по поводу этого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dyF4cUVirOhU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tDKJIzWrOhY"
   },
   "source": [
    "А здесь — вставить вашу любимую картинку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zjMKuHuCrOhY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "HW1-KasyanovIA.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
